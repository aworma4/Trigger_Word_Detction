{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34cbf84a-0b62-43bb-8928-77f4e1f8c72f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.linear = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        outputs = self.linear(self.fc(x))\n",
    "        alpha = torch.softmax(outputs, dim=1)\n",
    "        x = (x * alpha).sum(dim=1)\n",
    "        return x\n",
    "\n",
    "class KWSNet(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(self.params[\"num_features\"], self.params[\"cnn_channels\"],\n",
    "                      kernel_size=self.params[\"cnn_kernel_size\"], padding=self.params[\"cnn_kernel_size\"] // 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.rnn = nn.GRU(input_size=self.params[\"cnn_channels\"], hidden_size=self.params[\"gru_hidden_size\"],\n",
    "                          bidirectional=True, batch_first=True)\n",
    "        self.attention = Attention(self.params[\"gru_hidden_size\"] * 2, self.params[\"attention_hidden_size\"])\n",
    "        self.linear = nn.Linear(self.params[\"gru_hidden_size\"] * 2, 1 + 1, bias=False) # 1 keyword\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cnn(x).permute(0, 2, 1)\n",
    "        rnn_output, _ = self.rnn(conv)\n",
    "        linear_attn = self.linear(self.attention(rnn_output))\n",
    "        return torch.log_softmax(linear_attn, dim=1)\n",
    "\n",
    "    def inference(self, x: torch.Tensor, window_size: int):\n",
    "        if window_size > x.shape[2]:\n",
    "            window_size = x.shape[2]\n",
    "        probs = []\n",
    "        hidden = None\n",
    "        for i in range(window_size, x.shape[2] + 1, 50):\n",
    "            window = x[:, :, i - window_size:i]\n",
    "            window = self.cnn(window)\n",
    "            window = window.permute(0, 2, 1)\n",
    "            window, h = self.rnn(window, hidden)\n",
    "            window = self.attention(window)\n",
    "            window = self.linear(window)\n",
    "            p = torch.softmax(window, dim=1).squeeze()[1]\n",
    "            probs.append(p.item())\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf83ea28-0c73-42c2-89b7-9dbc4a1441d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\"num_features\": 40,\n",
    "          \"cnn_channels\": 16,\n",
    "          \"cnn_kernel_size\": 51,\n",
    "          \"gru_hidden_size\": 64,\n",
    "          \"attention_hidden_size\": 64,\n",
    "          \"window_size\": 100,\n",
    "          \"batch_size\": 64,\n",
    "          \"num_workers\": 8,\n",
    "          \"lr\": 0.001,\n",
    "          \"sample_rate\": 16000,\n",
    "          \"num_epochs\": 10,\n",
    "          \"noise_variance\": 0.05,\n",
    "          \"min_time_stretch\": 0.9,\n",
    "          \"max_time_stretch\": 1.1,\n",
    "          \"min_shift\": -3,\n",
    "          \"max_shift\": 3,\n",
    "          \"time_masking\": 1,\n",
    "          \"wandb_name\": \"KWSNet\",\n",
    "          \"clip_grad_norm\": 15,\n",
    "          \"vocab_size\": 120,\n",
    "          \"from_pretrained\": False,\n",
    "          \"model_path\": \"kws_model.pth\",\n",
    "          \"start_epoch\": 40,\n",
    "          \"path_to_file\": \"test_double.wav\",\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c41d30-4717-44a6-8118-a59a788adfca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "model = KWSNet(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d7f9717-3832-4625-8f59-d64e9ad7dca0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (1,40,801)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1                [-1, 16, 1]          32,656\n",
      "              ReLU-2                [-1, 16, 1]               0\n",
      "               GRU-3  [[-1, 1, 128], [-1, 2, 64]]               0\n",
      "            Linear-4                [-1, 1, 64]           8,256\n",
      "              Tanh-5                [-1, 1, 64]               0\n",
      "            Linear-6                 [-1, 1, 1]              64\n",
      "         Attention-7                  [-1, 128]               0\n",
      "            Linear-8                    [-1, 2]             256\n",
      "================================================================\n",
      "Total params: 41,232\n",
      "Trainable params: 41,232\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.12\n",
      "Params size (MB): 0.16\n",
      "Estimated Total Size (MB): 0.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#model.Conv\n",
    "print(f\"input shape: (1,{params['num_features']},{801})\")  \n",
    "summary(model, (params['num_features'],1))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f2fc971-4b62-4f29-b4d9-c05e756a033a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([801, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.zeros(801,40,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7024f72e-da5d-4d8c-a2ac-ee55efd245fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40*0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77520873-6a40-4561-a029-1a43d178dbfc",
   "metadata": {},
   "source": [
    "#build the network for this paper\n",
    "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43969.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f274b88c-db46-43c8-be89-cddc51294245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b2a59cb-423c-4aea-be40-ebe0e2db9030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "t = 32\n",
    "f = 40 \n",
    "\n",
    "X = torch.zeros(n,t,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "117e9bd9-3539-4da7-969b-8e1495941b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 33, 24])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Conv1d(16, 33, 3, stride=2)\n",
    "input = torch.randn(20, 16, 50)\n",
    "output = m(input)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e9692b-fc71-4884-83a4-34688527aac4",
   "metadata": {},
   "source": [
    "# try adding batch norm and dropout\n",
    "\n",
    "file:///C:/Users/AT030915/Downloads/Trigger_Word_Recognition_using_LSTM-1.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2fa4c5e-2cc5-4530-8f39-bac0dcc2eb65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TriggerWord_LSTM2(nn.Module):\n",
    "    '''\n",
    "    LSTM neural network for performing trigger word detection - based on paper Trigger_Word_Recognition_using_LSTM\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_freq, input_time , hidden_time, output_time, Conv_p, GRU_p):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        Create layers of the neural network - note freq/time denote the sizes of the 1st and 2nd dimensions respectively\n",
    "        '''\n",
    "        #save parameters here\n",
    "        self.input_freq = input_freq\n",
    "        self.input_time = input_time\n",
    "        self.hidden_time = hidden_time\n",
    "        self.output_time = output_time\n",
    "        self.Conv_p = Conv_p\n",
    "        self.GRU_p = GRU_p\n",
    "        \n",
    "        self.p_drop = 0.8\n",
    "        \n",
    "        \n",
    "        #CONV1D\n",
    "        self.Conv = nn.Conv1d(in_channels = input_freq, \n",
    "                              out_channels = Conv_p.out_channels,\n",
    "                              kernel_size = Conv_p.kernel_size, \n",
    "                              stride=Conv_p.stride)\n",
    "        #create Relu later\n",
    "        self.batch = nn.BatchNorm1d(num_feature=1)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.Dropout =  nn.Dropout(p=self.p_drop)\n",
    "\n",
    "        \n",
    "        #GRU\n",
    "        # calculate size of final dimension from conv1d - equation from documentation\n",
    "        #https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html\n",
    "        Conv_outsize = self.Conv(torch.ones([1,self.input_freq,self.input_time])).shape[2]\n",
    "        \n",
    "        self.GRU = nn.GRU(input_size =Conv_outsize, \n",
    "        hidden_size =hidden_time,\n",
    "        num_layers  = GRU_p.num_layers, \n",
    "        batch_first = GRU_p.batch_first, \n",
    "        dropout     = GRU_p.dropout)\n",
    "                \n",
    "        # DENSE\n",
    "        self.Dense = nn.Linear(in_features = hidden_time , out_features = output_time)\n",
    "\n",
    "        # Sigmoid layer\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def forward(self,xb):\n",
    "        '''\n",
    "        Apply the layers to the batch input\n",
    "        '''\n",
    "        out = self.Conv(xb)\n",
    "        \n",
    "        #apply relu and batch norm\n",
    "        out = self.batch(out)\n",
    "        out = self.ReLU(out)\n",
    "        out = self.Dropout(out)\n",
    "            \n",
    "        out, hidden_state = self.GRU(out)\n",
    "\n",
    "        out = self.Dense(out).squeeze(1)  #remove 1 singleton dimension - not the batch dimension\n",
    "\n",
    "        out = self.Sigmoid(out)\n",
    "               \n",
    "        return out\n",
    "        \n",
    "    \n",
    "def get_accuracy(y_true, y_prob,cutoff=0.8):\n",
    "    y_true = y_true.squeeze()\n",
    "    y_prob = y_prob.squeeze()\n",
    "    \n",
    "    \n",
    "    assert y_true.ndim == 1 and y_true.size() == y_prob.size()\n",
    "    y_prob = y_prob > cutoff\n",
    "    return (y_true == y_prob).sum().item() / y_true.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe29c2b7-c685-4019-8e3a-e9e104519b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### set devices \n",
    "class Params(object):\n",
    "\n",
    "    def __init__(self, batch_size, test_batch_size, number_frequencies, number_time_steps, epochs, lr, seed, cuda, log_interval,early_stopper_patience,early_stopper_min_delta, label_time,cutoff):\n",
    "        '''\n",
    "        Names self explanatory - seed = Random seed number, log_interval - the intervals at which the weights and biases will be recorded \n",
    "        '''\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.test_batch_size = test_batch_size\n",
    "\n",
    "        self.epochs = epochs\n",
    "\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.number_frequencies = number_frequencies\n",
    "        \n",
    "        self.number_time_steps = number_time_steps\n",
    "        \n",
    "\n",
    "        self.seed = seed\n",
    "\n",
    "        self.cuda = cuda\n",
    "\n",
    "        self.log_interval = log_interval\n",
    "\n",
    "        self.early_stopper_patience = early_stopper_patience\n",
    "        \n",
    "        self.early_stopper_min_delta = early_stopper_min_delta\n",
    "        \n",
    "        self.label_time = label_time\n",
    "        \n",
    "        self.cutoff = cutoff\n",
    "\n",
    "args =Params(batch_size = 4, test_batch_size = 4,\n",
    "             number_frequencies = 151,\n",
    "             number_time_steps = 400,\n",
    "             epochs = 200, lr =0.01, \n",
    "             seed = 1, cuda = False, \n",
    "             log_interval = 200,\n",
    "             early_stopper_patience = 5,\n",
    "             early_stopper_min_delta=0.01,\n",
    "             label_time = 801,#changed to same size as input time dimension of spectrogram.\n",
    "            cutoff =0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03e28052-4662-4909-a542-e1a7fa8b5228",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TriggerWord_LSTM2.__init__() missing 5 required positional arguments: 'input_time', 'hidden_time', 'output_time', 'Conv_p', and 'GRU_p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#model.Con\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m=\u001b[39m \u001b[43mTriggerWord_LSTM2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m input_freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m151\u001b[39m\n\u001b[0;32m      4\u001b[0m input_time  \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m801\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: TriggerWord_LSTM2.__init__() missing 5 required positional arguments: 'input_time', 'hidden_time', 'output_time', 'Conv_p', and 'GRU_p'"
     ]
    }
   ],
   "source": [
    "#model.Con\n",
    "model= TriggerWord_LSTM2(params)\n",
    "input_freq = 151\n",
    "input_time  = 801\n",
    "print(f\"input shape: (1,{input_freq},{input_time})\")  \n",
    "summary(model, (input_freq,input_time))     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d6216d8-2260-41b1-b7fd-98895c7942a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 100, 35, 45])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Learnable Parameters\n",
    "m = nn.BatchNorm2d(1)\n",
    "# Without Learnable Parameters\n",
    "m = nn.BatchNorm2d(100, affine=False)\n",
    "input = torch.randn(20, 100, 35, 45)\n",
    "output = m(input)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8fa3d-5890-49b8-b885-b2d15adbc0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
